apiVersion: apps/v1
kind: Deployment
metadata:
  name: solution-server
  namespace: solution-server
  labels:
    app: solution-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: solution-server
  template:
    metadata:
      labels:
        app: solution-server
    spec:
      volumes:
        - name: pg-data
          emptyDir: {} # PoC면 emptyDir로 충분, 재기동 시 데이터 초기화

        # LLM 모델 디렉터리 (노드 ↔ 컨테이너 매핑)
        - name: llm-models
          hostPath:
            path: /app/llm/models # 노드(호스트)에 모델이 있는 실제 경로
            type: DirectoryOrCreate

      containers:
        # 1) PostgreSQL 컨테이너
        - name: postgres
          image: postgres:15
          ports:
            - containerPort: 5432
          env:
            - name: POSTGRES_DB
              value: "logs_db"
            - name: POSTGRES_USER
              value: "postgres"
            - name: POSTGRES_PASSWORD
              value: "1q2w3e4r!"
          volumeMounts:
            - name: pg-data
              mountPath: /var/lib/postgresql/data
          resources:
            requests:
              cpu: "100m"
              memory: "256Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"

        # 2) 솔루션 서버(backend + llm + detect 통합 이미지)
        - name: solution-all
          image: solution-all:latest # 본인이 빌드한 이미지명으로 교체
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8000 # backend API
            - containerPort: 9000 # LLM API
          env:
            # --- 백엔드용 SQLAlchemy URL ---
            - name: DATABASE_URL
              value: "postgresql+psycopg2://postgres:1q2w3e4r!@127.0.0.1:5432/logs_db"

            # --- Detect 4개 모듈용 psycopg2 접속 정보 ---
            - name: DB_HOST
              value: "127.0.0.1"
            - name: DB_PORT
              value: "5432"
            - name: DB_NAME
              value: "logs_db"
            - name: DB_USER
              value: "postgres"
            - name: DB_PASS
              value: "1q2w3e4r!"

            # --- LLM 동작 모드 ---
            - name: LLM_MODE
              value: "local"

            # --- 로컬 모델 절대 경로 (파일명은 실제 존재하는 이름으로) ---
            - name: LOCAL_MODEL
              value: "/app/llm/models/mistral-7b-instruct-v0.2.Q4_K_M.gguf"

          volumeMounts:
            - name: llm-models
              mountPath: /app/llm/models
              readOnly: true

          resources:
            requests:
              cpu: "1"
              memory: "1Gi"
            limits:
              cpu: "2" # vCPU 2개까지
              memory: "6Gi"
