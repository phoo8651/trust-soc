

## ğŸ“Œ README.md (ë¦¬ëˆ…ìŠ¤ ì„¤ì¹˜ + ì‹¤í–‰ ê°€ì´ë“œ)

````markdown
# ğŸ” Trust-SOC LLM Advisor  
> Incident Advisor API (LLM + RAG + ATT&CK ë§¤í•‘ + HIL)

ì´ í”„ë¡œì íŠ¸ëŠ” ë³´ì•ˆ ì´ë²¤íŠ¸ë¥¼ ìë™ ë¶„ì„í•˜ê³  MITRE ATT&CK ê¸°ë°˜ ë§¤í•‘ ë° Human-in-the-Loop(HIL) ê²€ì¦ ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤.  
ë¡œì»¬ LLM + RAG + ê·œì¹™ ë§¤í•‘ì„ ê²°í•©í•œ **í•˜ì´ë¸Œë¦¬ë“œ SOC ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸** ì…ë‹ˆë‹¤.

---

## ğŸš€ Features

- ğŸ¤– **ë¡œì»¬ LLM ë¶„ì„ (Mistral 7B)**
- ğŸ“š **RAG ê¸°ë°˜ ê·¼ê±° ë¬¸ì„œ ì¸ìš©**
- ğŸ” **ë¯¼ê° ë°ì´í„° ë§ˆìŠ¤í‚¹**
- ğŸ¯ **MITRE ATT&CK Hybrid ë§¤í•‘**
- ğŸ‘¨â€ğŸ’» **HIL ìŠ¹ì¸ + Webhook í†µí•©**
- ğŸ“Œ **Confidence Guardrails**

---

## ğŸ› ï¸ Installation (Linux)

### 1ï¸âƒ£ Clone the Repository

```bash
cd trust-soc/llm
````

### 2ï¸âƒ£ Run Install Script

```bash
chmod +x install.sh
./install.sh
```

ğŸ“Œ ì„¤ì¹˜ ë‚´ìš©

* Python3 + venv í™˜ê²½ êµ¬ì„±
* llama-cpp-python ì„¤ì¹˜
* ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ (Mistral 7B Q4_K_M)
* `.env` êµ¬ì„±

---

## â–¶ï¸ Running the API Server

```bash
source venv/bin/activate
uvicorn llm.advisor_api:app --reload --host 0.0.0.0 --port 10555
```

### ğŸ“Œ Server URL

```
http://localhost:10555
```

### ğŸ“š Swagger UI

```
http://localhost:10555/docs
```

---

## ğŸ” Example API Request

**POST /analyze**

```json
{
  "event_text": "Failed SSH login from 10.0.0.5 for user root",
  "evidences": [
    {
      "type": "raw",
      "ref_id": "E1",
      "source": "auth.log",
      "offset": 0,
      "length": 120,
      "sha256": "abcdef123456",
      "snippet": "Failed SSH login from 10.0.0.5"
    }
  ]
}
```

---

## ğŸ§ª Test Webhook Endpoint

ì„œë²„ëŠ” HIL ì‹œ ë‹¤ìŒ URLë¡œ Webhook ì „ì†¡í•©ë‹ˆë‹¤:

```
POST http://localhost:10555/webhooks/test-receiver
```

í—¤ë”: `X-Signature (sha256)` ê²€ì¦ ì ìš©ë¨.

---

## âš™ï¸ Environment Variables (.env)


| ë³€ìˆ˜ëª…            | ì„¤ëª…                   |
| ---------------- | -------------------- |
| `LLM_MODE`       | `local` or `gateway` |
| `LOCAL_MODEL`    | ë¡œì»¬ LLM ëª¨ë¸ ê²½ë¡œ         |
| `WEBHOOK_SECRET` | Webhook ì„œëª… ê²€ì¦ Key    |

---

## ğŸ“Œ Project Structure

```
llm/
â”œâ”€â”€ advisor_api.py         # FastAPI ì—”ë“œí¬ì¸íŠ¸
â”œâ”€â”€ attack_mapper.py       # MITRE ATT&CK ë§¤í•‘ ì—”ì§„
â”œâ”€â”€ install.sh             # Linux Setup Script (â¬…ï¸)
â”œâ”€â”€ local_llm_PoC.py       # Llama/Dummy LLM Wrapper
â”œâ”€â”€ rag/                   # RAG Engine + Vector Search
â”œâ”€â”€ utils/                 # Confidence / JSON Handling
â”œâ”€â”€ masking/               # PII/Secret Masking
â””â”€â”€ prompt_templates/      # LLM Prompt Templates
```





