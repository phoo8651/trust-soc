import time
import logging
import hashlib
import asyncio
from typing import Dict, Any

# [ìˆ˜ì •] ì˜¬ë°”ë¥¸ íŒ¨í‚¤ì§€ ê²½ë¡œë¡œ ë³€ê²½
from app.llm.local_llm_PoC import DummyLocalLLM, LocalMistralLLM

logger = logging.getLogger("ModelGateway")


class ModelGateway:
    def __init__(
        self,
        local_model_path: str,
        use_real_llm: bool = True,
        enable_fallback: bool = True,
        timeout: float = 120,  # [ìˆ˜ì •] íƒ€ì„ì•„ì›ƒ 60 -> 120ì´ˆ (CPU ëª¨ë“œ ê³ ë ¤)
    ):
        self.timeout = timeout
        self.enable_fallback = enable_fallback
        self.mock_mode = False

        if use_real_llm:
            try:
                self.llm = LocalMistralLLM(model_path=local_model_path)
            except Exception as e:
                logger.error(f"âŒ Failed to load Real LLM: {e}")
                if not enable_fallback:
                    raise e

                logger.warning("âš ï¸ Switching to Dummy LLM due to load failure.")
                self.llm = DummyLocalLLM()
                self.mock_mode = True
        else:
            self.llm = DummyLocalLLM()
            self.mock_mode = True

    async def generate(self, prompt: str) -> str:
        start_time = time.time()
        try:
            if self.mock_mode:
                return self.llm.generate(prompt)

            # ì‹¤ì œ LLMì€ ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ (Non-blocking)
            return await asyncio.wait_for(
                asyncio.to_thread(self.llm.generate, prompt), timeout=self.timeout
            )

        except Exception as e:
            # [ìˆ˜ì •] ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ë” ëª…í™•í•˜ê²Œ ì¶œë ¥
            logger.error(f"âŒ Local LLM Runtime Error: {e}")

            if self.enable_fallback:
                logger.info("ğŸ”„ Activating Fallback Mechanism (Dummy Response)")
                return DummyLocalLLM().generate(prompt)
            raise e
        finally:
            duration = time.time() - start_time
            logger.info(f"â±ï¸ LLM Processing Time: {duration:.2f}s")
