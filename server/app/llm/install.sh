#!/bin/bash

echo "=============================="
echo "ğŸ›   trust-soc LLM Install Script"
echo "ğŸ“Œ Ubuntu/Debian Linux Supported"
echo "=============================="
sleep 1

# ===============================
# 1) ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
# ===============================
echo "ğŸ“¦ Installing dependencies..."
sudo apt update
sudo apt install -y python3 python3-pip python3-venv build-essential git wget curl

# ===============================
# 2) Python venv ìƒì„±
# ===============================
echo "ğŸ Setting up Python virtual environment..."
python3 -m venv venv
source venv/bin/activate

# ===============================
# 3) PyPI requirements ì„¤ì¹˜
# ===============================
echo "ğŸ“¦ Installing Python packages..."
pip install --upgrade pip

# requirements.txtëŠ” repo root (../)
pip install -r ../requirements.txt

# ===============================
# 4) llama-cpp ì„¤ì¹˜ (CPU ê¸°ë³¸)
# ===============================
echo "ğŸ¤– Installing llama-cpp-python (CPU mode, GGUF runtime for Mistral)..."
pip install llama-cpp-python --verbose --force-reinstall --no-cache-dir

# ===============================
# 5) ëª¨ë¸ ë””ë ‰í† ë¦¬ (llm/models/)
# ===============================
echo "ğŸ“‚ Preparing model directory..."
mkdir -p models
cd models

# ===============================
# 6) ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ
# ===============================
MODEL_URL="https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf"

if [ ! -f "mistral-7b-instruct-v0.2.Q4_K_M.gguf" ]; then
  echo "â†“ Downloading model (â‰ˆ 4GB)..."
  wget $MODEL_URL
else
  echo "âœ” Model already exists, skipping download."
fi

# ëŒì•„ê°€ê¸° (llm/)
cd ..

# ===============================
# 7) í™˜ê²½ ë³€ìˆ˜ ìƒì„± (.env in llm/)
# ===============================
echo "ğŸ”§ Setting environment variables..."
cat <<EOF > .env
LLM_MODE=local
LOCAL_MODEL=./models/mistral-7b-instruct-v0.2.Q4_K_M.gguf
WEBHOOK_SECRET=change_me_please
EOF

echo "=============================="
echo "ğŸ‰ Installation Completed!"
echo "ğŸš€ Run with:"
echo "ğŸ‘‰  source venv/bin/activate && uvicorn llm.advisor_api:app --reload --port 10555"
echo "=============================="
