# llm/locol_llm.PoC.py
from llama_cpp import Llama


MODEL_PATH = "C:/Users/ngh11/trust-soc/llm/models/mistral-7b-instruct-v0.2.Q4_K_M.gguf"

# ëª¨ë¸ ë¡œë“œ
llm = Llama(model_path=MODEL_PATH, n_ctx=2048, n_threads=6)

# í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
prompt = """SYSTEM:
ë‹¹ì‹ ì€ ë³´ì•ˆ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ëŠ” AIì…ë‹ˆë‹¤.
ë‹¤ìŒ ë¡œê·¸ì˜ ê³µê²© ì§•í›„ë¥¼ ìš”ì•½í•˜ì„¸ìš”.

USER:
[EVENT]
2025-11-02 14:11:33 - POST /app/login - suspicious payload detected

[TOP-K EVIDENCES]
ref_id: log_001
type: raw
source: web_log
snippet: "payload contains eval() function"

OUTPUT_SCHEMA:
{
  "summary": "",
  "confidence_explanation": "",
  "evidence_refs_used": []
}
"""

print("ğŸ§  LLM ì‘ë‹µ ìƒì„± ì¤‘...")
response = llm(prompt=prompt, max_tokens=256, temperature=0.7, stop=["</s>"])
print(response["choices"][0]["text"])

import json

class DummyLocalLLM:
    def generate(self, prompt: str) -> str:
        # promptë¥¼ ë°›ì•„ì„œ JSON ë¬¸ìì—´ì„ ë¦¬í„´ (ì‹¤ì œ LLM í‰ë‚´)
        fake = {
            "summary": "Spring4Shell ì˜ì‹¬ ê³µê²© ë°œìƒ",
            "attack_mapping": ["T1190 - Exploit Public-Facing Application"],
            "recommended_actions": ["WAF ë£° ê°•í™”", "ì·¨ì•½ ë²„ì „ íŒ¨ì¹˜ ì ìš©"],
            "confidence": 0.88,
            "evidence_refs": [
                {
                    "type": "yara",
                    "ref_id": "yara_001",
                    "source": "web_log",
                    "offset": 123,
                    "length": 256,
                    "sha256": "aabbccddeeff1122334455",
                    "rule_id": "SPRING4SHELL_WEB"
                }
            ],
            "hil_required": False
        }
        return json.dumps(fake, ensure_ascii=False)